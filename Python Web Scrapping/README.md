## Web Scraping Project - Python
Welcome to my Web Scraping Project! This project focuses on scraping data from two different websites using Python, BeautifulSoup, and requests library. The scraped data is then cleaned and saved as CSV files for further analysis.

### Files
This project consists of the following files:

`All-time_EPL_Table_Scraping.ipynb`: This Jupyter Notebook file contains the Python code for scraping the all-time English Premier League (EPL) table from [Wikipedia](https://en.wikipedia.org/wiki/Premier_League_records_and_statistics). 

`VN_International_Debt_Statistics_Scraping.ipynb`: This Jupyter Notebook file contains the Python code for scraping Vietnam's international debt statistics from [The World Bank](https://datatopics.worldbank.org/debt/ids/countryanalytical/VNM).

The BeautifulSoup library is used to extract the relevant data, requests library is used to fetch the HTML content, and data cleaning techniques are applied to format the data. The output of these file are saved as `All-time_EPL_Table.csv` and `VN_International_Debt_Statistics.csv`.

### Dataset URLs
The datasets used in this project can be accessed from the following URLs:

[All-time EPL Table Dataset](https://en.wikipedia.org/wiki/Premier_League_records_and_statistics)

[VN International Debt Statistics Dataset](https://datatopics.worldbank.org/debt/ids/countryanalytical/VNM)

The cleaned datasets are included in this repository. However, please note the datasets above may have been updated since the completion of this project.

### How to Run the Project
To run this project on your machine, follow these steps:

1. Ensure that you have Python installed on your system along with the necessary libraries (BeautifulSoup, requests).
2. Clone this repository to your local machine or download the project files.
3. Open the Jupyter Notebook files (`All-time_EPL_Table_Scraping.ipynb` and `VN_International_Debt_Statistics_Scraping.ipynb`) using Jupyter Notebook or any other compatible environment.
4. Execute the code cells in the notebooks to perform the web scraping and data cleaning.
5. The output CSV files (`All-time_EPL_Table.csv` and `VN_International_Debt_Statistics.csv`) will be generated upon executing the code. It is recommended that you change my file export path to your own.

You can now use these CSV files for further analysis or visualization in your preferred data analysis tool.
Please refer to the specific Jupyter Notebook files for more detailed information on the web scraping process and data cleaning techniques applied.

### Contact Information
If you have any questions, feedback, or would like to connect regarding the Web Scraping Project, feel free to reach out to me. You can contact me at thaian201001@gmail.com or connect with me on [LinkedIn](https://www.linkedin.com/in/nguyenchonthaian/).

Thank you for exploring the Web Scraping Project! I hope you find the scraped datasets useful for your analysis and insights.
